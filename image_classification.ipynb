{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries"
      ],
      "metadata": {
        "id": "yRB3VQ32HLoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import requests\n",
        "import gc\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import wandb\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB3, DenseNet169, Xception, ConvNeXtBase\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED = 244\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "wH7LAkk3HPYj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Dataset"
      ],
      "metadata": {
        "id": "GGvsAt4fHSOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Define GitHub Repo & Folder Path"
      ],
      "metadata": {
        "id": "kfQwJ27THqM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_REPO = \"prattapong/Commercial-Airplane-Model-Image-Classification\"\n",
        "GITHUB_FOLDER = \"images\"\n",
        "GITHUB_API_URL = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{GITHUB_FOLDER}\""
      ],
      "metadata": {
        "id": "glwG9gyqHW_H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Fetch Image URLs and Load Image"
      ],
      "metadata": {
        "id": "8n61Mj3zHzKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_sizes = []\n",
        "color_counts = {\"RGB\": 0, \"Grayscale\": 0}"
      ],
      "metadata": {
        "id": "iR8xmDld8NA_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Image URLs Automatically\n",
        "def get_image_urls():\n",
        "    response = requests.get(GITHUB_API_URL)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Error fetching images: {response.json()}\")\n",
        "\n",
        "    image_urls = {}\n",
        "    for folder in response.json():\n",
        "        if folder[\"type\"] == \"dir\":  # Ensure it's a folder (A350, B787, A320)\n",
        "            class_name = folder[\"name\"]\n",
        "            image_urls[class_name] = []\n",
        "            folder_url = folder[\"url\"]\n",
        "\n",
        "            # Fetch image files in each class folder\n",
        "            folder_response = requests.get(folder_url)\n",
        "            if folder_response.status_code == 200:\n",
        "                for file in folder_response.json():\n",
        "                    if file[\"name\"].lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                        image_urls[class_name].append(file[\"download_url\"])\n",
        "\n",
        "    return image_urls\n",
        "\n",
        "# Load Images Function (Now storing original info before resizing)\n",
        "def load_images(image_urls):\n",
        "    IMG_SIZE = (224, 224)  # Resize all images to 224x224\n",
        "    X, y = [], []\n",
        "\n",
        "    total_images = sum(len(urls) for urls in image_urls.values())  # Total number of images\n",
        "    progress_bar = tqdm(total=total_images, desc=\"Loading Images\", unit=\"img\")\n",
        "\n",
        "    for label, urls in image_urls.items():\n",
        "        for url in urls:\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "\n",
        "                # Store original size and color type\n",
        "                original_sizes.append(img.size)  # (width, height)\n",
        "                if img.mode == \"L\":\n",
        "                    color_counts[\"Grayscale\"] += 1\n",
        "                else:\n",
        "                    color_counts[\"RGB\"] += 1\n",
        "\n",
        "                # Convert to RGB and resize\n",
        "                img = img.convert(\"RGB\").resize(IMG_SIZE)\n",
        "                X.append(np.array(img) / 255.0)  # Normalize\n",
        "                y.append(label)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {url}: {e}\")\n",
        "\n",
        "            progress_bar.update(1)  # Update progress bar\n",
        "\n",
        "    progress_bar.close()\n",
        "    return np.array(X), pd.Categorical(y).codes"
      ],
      "metadata": {
        "id": "AVWh-JyZH8i9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_urls = get_image_urls()\n",
        "X, y = load_images(image_urls)  # Load images first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_vXZtrXlX6e",
        "outputId": "f0398670-af5b-4e73-bf7e-13bba939c74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Images:  63%|██████▎   | 379/605 [01:43<01:01,  3.65img/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. EDA"
      ],
      "metadata": {
        "id": "_DcGH7Zi3XVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Display Original Image Size Distribution as DataFrame\n",
        "def display_original_image_sizes(original_sizes):\n",
        "    size_counts = Counter(tuple(size) for size in original_sizes)\n",
        "    size_df = pd.DataFrame(size_counts.items(), columns=[\"Image Size\", \"Frequency\"])\n",
        "    size_df = size_df.sort_values(by=\"Frequency\", ascending=False).reset_index(drop=True)\n",
        "    size_df[\"Percentage\"] = (size_df[\"Frequency\"] / size_df[\"Frequency\"].sum()) * 100\n",
        "    print(size_df)\n",
        "\n",
        "# Function to Show Color vs Grayscale Distribution\n",
        "def plot_color_distribution(color_counts):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.pie(color_counts.values(), labels=color_counts.keys(), autopct=\"%1.1f%%\", colors=[\"lightblue\", \"gray\"])\n",
        "    plt.title(\"Color vs. Grayscale Images (Before Processing)\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to Show Class Distribution After Processing\n",
        "def plot_class_distribution(y):\n",
        "    class_counts = Counter(y)\n",
        "    class_labels = sorted(class_counts.keys())  # Ensure ordered class names\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()), palette=\"viridis\")\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Number of Images\")\n",
        "    plt.title(\"Class Distribution in Dataset\")\n",
        "    plt.xticks(range(len(class_labels)), class_labels, rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to Show Sample Images After Processing\n",
        "def show_sample_images(X, y, class_labels, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    sampled_indices = np.random.choice(len(X), num_images, replace=False)\n",
        "\n",
        "    for i, idx in enumerate(sampled_indices):\n",
        "        axes[i].imshow(X[idx])\n",
        "        axes[i].axis(\"off\")\n",
        "        axes[i].set_title(f\"Class: {class_labels[y[idx]]}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Perform Full EDA\n",
        "def perform_eda(X, y, class_labels):\n",
        "    print(f\"Total images after processing: {len(X)}\")\n",
        "    print(f\"Processed image shape: {X[0].shape}\")  # Should be (224, 224, 3)\n",
        "\n",
        "    display_original_image_sizes(original_sizes)\n",
        "    plot_color_distribution(color_counts)\n",
        "\n",
        "    plot_class_distribution(y)\n",
        "    show_sample_images(X, y, class_labels)"
      ],
      "metadata": {
        "id": "qUzJRJBt9FgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"Class A\", \"Class B\", \"Class C\"]\n",
        "perform_eda(X, y, class_labels)"
      ],
      "metadata": {
        "id": "EzeMGXgM3ZNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data-preprocessing"
      ],
      "metadata": {
        "id": "o2HlslEEIICa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_edges(X):\n",
        "    edge_images = []\n",
        "\n",
        "    for img in X:\n",
        "        # Convert image to grayscale\n",
        "        gray_img = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Apply Canny edge detection\n",
        "        edges = cv2.Canny(gray_img, 1, 20)\n",
        "\n",
        "        # Convert back to RGB format to maintain consistency\n",
        "        edges_rgb = cv2.cvtColor(edges, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Normalize to [0, 1]\n",
        "        edge_images.append(edges_rgb / 255.0)\n",
        "\n",
        "    return np.array(edge_images)"
      ],
      "metadata": {
        "id": "aUPzJWBo9gPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_edge = preprocess_edges(X)"
      ],
      "metadata": {
        "id": "SZzU785i90pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_original_vs_edge(X, X_edge, index):\n",
        "    # Plot original image (X[0]) and edge-detected image (X_edge[0])\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Original Image\n",
        "    axes[0].imshow(X[index])\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "\n",
        "    # Edge-Detected Image\n",
        "    axes[1].imshow(X_edge[index])\n",
        "    axes[1].axis(\"off\")\n",
        "    axes[1].set_title(\"Edge-Detected Image\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you already have X (original images) and X_edge (edge-detected images)\n",
        "plot_original_vs_edge(X, preprocess_edges(X), index = 210)"
      ],
      "metadata": {
        "id": "1ZPcWyDu9-Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(X_train):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    return datagen"
      ],
      "metadata": {
        "id": "4Dku3IEFIOwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train model"
      ],
      "metadata": {
        "id": "1V21idVpIl1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 List 5 pre-trained models"
      ],
      "metadata": {
        "id": "gJqMdlyIBeK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS = {\n",
        "    \"ResNet50\": ResNet50,\n",
        "    \"VGG16\": VGG16,\n",
        "    \"DenseNet169\": DenseNet169,\n",
        "    \"Xception\": Xception,\n",
        "    \"ConvNeXtBase\": ConvNeXtBase\n",
        "}"
      ],
      "metadata": {
        "id": "80TWiYyFBo4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Initiate training loop"
      ],
      "metadata": {
        "id": "u4xXQzZrPWqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdI2QyIrpTO0"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(model_name, X, y, batch_size, epochs, learning_rate, dropout_rate, num_unfreezed_layer=0):\n",
        "    print(f'*** Training {model_name} ***')\n",
        "    print(f'- Batch Size: {batch_size}')\n",
        "    print(f'- LR: {learning_rate}')\n",
        "    print(f'- Dropout: {dropout_rate}')\n",
        "    print(f'- Last \"{num_unfreezed_layer}\" layers unfreezed\\n')\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        "    )\n",
        "\n",
        "    # Define Input Layer\n",
        "    input_tensor = Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Load Pretrained Model\n",
        "    base_model = MODELS[model_name](weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "    # Unfreeze Layers If Needed\n",
        "    if num_unfreezed_layer == 0:\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in base_model.layers[-num_unfreezed_layer:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # Add Custom Classification Head\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    output_layer = Dense(len(np.unique(y)), activation=\"softmax\")(x)\n",
        "\n",
        "    # Build Model\n",
        "    model = Model(inputs=input_tensor, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # Data Augmentation\n",
        "    datagen = augment_data(X_train)\n",
        "\n",
        "    # Model Checkpointing\n",
        "    model_path = f'best_{model_name}.keras'  # Use .keras format\n",
        "    checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    # Train Model\n",
        "    history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs,\n",
        "                        callbacks=[checkpoint])\n",
        "\n",
        "    # Load Best Model (Fix for ConvNeXtBase)\n",
        "    custom_objects = get_custom_objects() if model_name == \"ConvNeXtBase\" else None\n",
        "    best_model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "    # Evaluate on Test Data\n",
        "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "    print(f\"\\n{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model_name, test_accuracy, history\n",
        "\n",
        "def compare_models(X, y, learning_rates, dropout_rates, batch_sizes, num_unfreezed_layers, epochs=50):\n",
        "    results = []\n",
        "\n",
        "    # Loop through all model hyperparameters with tqdm progress bar\n",
        "    for model_name in MODELS.keys():\n",
        "        for lr in learning_rates:\n",
        "            for dr in dropout_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    for num_unfreezed_layer in num_unfreezed_layers:\n",
        "                        result = train_and_evaluate_model(model_name, X, y, batch_size, epochs, lr, dr, num_unfreezed_layer)\n",
        "                        results.append(result)\n",
        "                        print('------------------------------------------------------------------------\\n')\n",
        "\n",
        "    # Sort models by accuracy\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(\"\\nModel Performance Ranking:\")\n",
        "    for rank, (model_name, accuracy, _) in enumerate(results, 1):\n",
        "        print(f\"{rank}. {model_name}: {accuracy:.4f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rrOJ7-6epTO3"
      },
      "outputs": [],
      "source": [
        "# image_urls = get_image_urls()\n",
        "# X, y = load_images(image_urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Set Hyper-parameter"
      ],
      "metadata": {
        "id": "OwwQZAAiRlKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_unfreezed_layers = [0]\n",
        "learning_rates = [0.0001]\n",
        "dropout_rates = [0.2]\n",
        "batch_sizes = [8]"
      ],
      "metadata": {
        "id": "f33W2VbrQjkr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Train all models and parameters"
      ],
      "metadata": {
        "id": "Ahnvvdu-Safq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best_model = compare_models(\n",
        "#     X = X,\n",
        "#     y = y,\n",
        "#     epochs = 5,\n",
        "\n",
        "#     ############## Hyper-parameter ##############\n",
        "#     learning_rates = learning_rates,\n",
        "#     dropout_rates = dropout_rates,\n",
        "#     batch_sizes = batch_sizes,\n",
        "#     num_unfreezed_layers = num_unfreezed_layers\n",
        "# )"
      ],
      "metadata": {
        "id": "aP6gUIceJRCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 WandB"
      ],
      "metadata": {
        "id": "o2qV682IOaHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize WandB\n",
        "def init_wandb(project_name=\"commercial-aircraft-model-classification\", config=None):\n",
        "    wandb.init(project=project_name, config=config)\n",
        "\n",
        "# Log Hyperparameters and Metrics to WandB\n",
        "def log_hyperparameters(config, history, test_accuracy):\n",
        "    wandb.config.update(config)  # Log the hyperparameters\n",
        "    wandb.log({\n",
        "        \"accuracy\": history.history['accuracy'][-1],  # Log training accuracy\n",
        "        \"val_accuracy\": history.history['val_accuracy'][-1],  # Log validation accuracy\n",
        "        \"test_accuracy\": test_accuracy,  # Log test accuracy\n",
        "        \"loss\": history.history['loss'][-1],  # Log training loss\n",
        "        \"val_loss\": history.history['val_loss'][-1],  # Log validation loss\n",
        "    })\n",
        "\n",
        "# Function to Train and Evaluate Model with WandB Logging\n",
        "def train_and_evaluate_model_with_wandb(model_name, X, y, batch_size, epochs, learning_rate, dropout_rate, num_unfreezed_layer=0):\n",
        "    print(f'*** Training {model_name} with WandB ***')\n",
        "    print(f'- Batch Size: {batch_size}')\n",
        "    print(f'- LR: {learning_rate}')\n",
        "    print(f'- Dropout: {dropout_rate}')\n",
        "    print(f'- Last \"{num_unfreezed_layer}\" layers unfreezed\\n')\n",
        "\n",
        "    # Hyperparameters to log with WandB\n",
        "    config = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"dropout_rate\": dropout_rate,\n",
        "        \"num_unfreezed_layer\": num_unfreezed_layer\n",
        "    }\n",
        "\n",
        "    # Initialize WandB for logging\n",
        "    init_wandb(config=config)\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        "    )\n",
        "\n",
        "    # Define Input Layer\n",
        "    input_tensor = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Load Pretrained Model\n",
        "    base_model = MODELS[model_name](weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "    # Unfreeze Layers If Needed\n",
        "    if num_unfreezed_layer == 0:\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in base_model.layers[-num_unfreezed_layer:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # Add Custom Classification Head\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    output_layer = tf.keras.layers.Dense(len(np.unique(y)), activation=\"softmax\")(x)\n",
        "\n",
        "    # Build Model\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=output_layer)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # Data Augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        rescale=1./255,  # Rescale pixel values to [0, 1]\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    # Model Checkpointing (Save best model)\n",
        "    model_path = f'best_{model_name}.keras'  # Use .keras format\n",
        "    checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    # Train Model\n",
        "    history = model.fit(\n",
        "        datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=epochs,\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "\n",
        "    # Load Best Model\n",
        "    custom_objects = get_custom_objects() if model_name == \"ConvNeXtBase\" else None\n",
        "    best_model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "    # Evaluate on Test Data\n",
        "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "    print(f\"\\n{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Log to WandB\n",
        "    log_hyperparameters(config, history, test_accuracy)\n",
        "\n",
        "    # Clear session and collect garbage to free memory\n",
        "    K.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return model_name, test_accuracy, history"
      ],
      "metadata": {
        "id": "IR44QBytLs-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters manually\n",
        "model_name = \"ResNet50\"  # Example model\n",
        "batch_size = 8\n",
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "dropout_rate = 0.5\n",
        "num_unfreezed_layer = 2\n",
        "\n",
        "# Train and evaluate model with WandB logging\n",
        "train_and_evaluate_model_with_wandb(\n",
        "    model_name=model_name,\n",
        "    X=X,\n",
        "    y=y,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    dropout_rate=dropout_rate,\n",
        "    num_unfreezed_layer=num_unfreezed_layer\n",
        ")"
      ],
      "metadata": {
        "id": "0VItSFxdLzxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"commercial-aircraft-model-classification\")\n",
        "\n",
        "# Start sweep jobs\n",
        "wandb.agent(sweep_id, function=train_and_evaluate_model_with_wandb, count=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y0bzZbqFLxYU",
        "outputId": "cd693295-10bd-42c6-86f0-0bfa13b3d8e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: i5gztlyh\n",
            "Sweep URL: https://wandb.ai/6620422008-nida-business-school/commercial-aircraft-model-classification/sweeps/i5gztlyh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nobbze55 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_unfreezed_layer: 2\n",
            "ERROR:wandb.agents.pyagent:Run nobbze55 errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "    self._function()\n",
            "TypeError: train_and_evaluate_model_with_wandb() missing 7 required positional arguments: 'model_name', 'X', 'y', 'batch_size', 'epochs', 'learning_rate', and 'dropout_rate'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run nobbze55 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: train_and_evaluate_model_with_wandb() missing 7 required positional arguments: 'model_name', 'X', 'y', 'batch_size', 'epochs', 'learning_rate', and 'dropout_rate'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xb2ye22r with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_unfreezed_layer: 5\n",
            "ERROR:wandb.agents.pyagent:Run xb2ye22r errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "    self._function()\n",
            "TypeError: train_and_evaluate_model_with_wandb() missing 7 required positional arguments: 'model_name', 'X', 'y', 'batch_size', 'epochs', 'learning_rate', and 'dropout_rate'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run xb2ye22r errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: train_and_evaluate_model_with_wandb() missing 7 required positional arguments: 'model_name', 'X', 'y', 'batch_size', 'epochs', 'learning_rate', and 'dropout_rate'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1x9l897j with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_unfreezed_layer: 0\n",
            "ERROR:wandb.agents.pyagent:Run 1x9l897j errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "    self._function()\n",
            "TypeError: train_and_evaluate_model_with_wandb() missing 7 required positional arguments: 'model_name', 'X', 'y', 'batch_size', 'epochs', 'learning_rate', and 'dropout_rate'\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1x9l897j errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: train_and_evaluate_model_with_wandb() missing 7 required positional arguments: 'model_name', 'X', 'y', 'batch_size', 'epochs', 'learning_rate', and 'dropout_rate'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "ERROR:wandb.agents.pyagent:Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Show result of a sample"
      ],
      "metadata": {
        "id": "lYXfZpDkND7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradcam(model, img_array, layer_name):\n",
        "    \"\"\"\n",
        "    Computes Grad-CAM heatmap for a given image and model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model\n",
        "    - img_array: Preprocessed image array with shape (1, height, width, channels)\n",
        "    - layer_name: The name of the convolutional layer to extract gradients from\n",
        "\n",
        "    Returns:\n",
        "    - heatmap: Grad-CAM heatmap (numpy array)\n",
        "    \"\"\"\n",
        "    grad_model = Model(inputs=model.input, outputs=[model.get_layer(layer_name).output, model.output])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    for i in range(conv_outputs.shape[-1]):\n",
        "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(conv_outputs, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)  # ReLU\n",
        "    heatmap /= np.max(heatmap)  # Normalize\n",
        "    return heatmap\n",
        "\n",
        "def overlay_heatmap(img, heatmap, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Overlays the Grad-CAM heatmap on the original image.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Original image\n",
        "    - heatmap: Grad-CAM heatmap\n",
        "    - alpha: Transparency factor (default=0.5)\n",
        "\n",
        "    Returns:\n",
        "    - Superimposed image with heatmap\n",
        "    \"\"\"\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "    return superimposed_img\n",
        "\n",
        "def show_prediction_with_gradcam(model, X, y, index, class_labels, layer_name=\"convnext_base_stage4_block2_layer_scale\"):\n",
        "    \"\"\"\n",
        "    Displays an image with the model's prediction, actual label, and Grad-CAM visualization.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model\n",
        "    - X: NumPy array of images\n",
        "    - y: NumPy array of actual labels\n",
        "    - index: Index of the image to display\n",
        "    - class_labels: List of class names corresponding to label indices\n",
        "    - layer_name: Name of the convolutional layer to compute Grad-CAM from (default: last ConvNeXt block)\n",
        "    \"\"\"\n",
        "    sample_image = np.array(X[index])\n",
        "    sample_input = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    predictions = model.predict(sample_input)\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    actual_class = y[index]\n",
        "\n",
        "    predicted_label = class_labels[predicted_class]\n",
        "    actual_label = class_labels[actual_class]\n",
        "\n",
        "    # Compute Grad-CAM\n",
        "    heatmap = compute_gradcam(model, sample_input, layer_name)\n",
        "    superimposed_img = overlay_heatmap((sample_image * 255).astype(np.uint8), heatmap)\n",
        "\n",
        "    # Display Results\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    # Original Image\n",
        "    axes[0].imshow(sample_image)\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[0].set_title(f\"Original Image\\nActual: {actual_label}\\nPredicted: {predicted_label}\", fontsize=12, color=\"blue\")\n",
        "\n",
        "    # Grad-CAM Overlay\n",
        "    axes[1].imshow(superimposed_img)\n",
        "    axes[1].axis(\"off\")\n",
        "    axes[1].set_title(\"Grad-CAM Visualization\", fontsize=12, color=\"red\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3o018kM6J0F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"Airbus A320\", \"Airbus A350\", \"Boeing 787\"]\n",
        "# best_model = tf.keras.models.load_model(\"best_DenseNet169.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "cmE4GLemLut0",
        "outputId": "58d1c55b-64b0-4c3c-e05a-060a0de81be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'best_DenseNet169.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-597daf44b03a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Airbus A320\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Airbus A350\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Boeing 787\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_DenseNet169.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'best_DenseNet169.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [0,10,402,405,500, 600]:\n",
        "    show_prediction(best_model, X, y, index=i, class_labels=class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "SPUxEBgmbz8C",
        "outputId": "cbf80df2-bf9c-4d17-c52a-eff02cde5d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'predict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-05c91130c4e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m402\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m405\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mshow_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-d18a2b6069c8>\u001b[0m in \u001b[0;36mshow_prediction\u001b[0;34m(model, X, y, index, class_labels)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msample_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mactual_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "id": "hbGq6N81MqyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6a63c2-6c67-40ac-e4b6-815d422072f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('DenseNet169',\n",
              "  0.6363636255264282,\n",
              "  <keras.src.callbacks.history.History at 0x78474e749150>),\n",
              " ('Xception',\n",
              "  0.4958677589893341,\n",
              "  <keras.src.callbacks.history.History at 0x784605569ed0>),\n",
              " ('ConvNeXtBase',\n",
              "  0.4628099203109741,\n",
              "  <keras.src.callbacks.history.History at 0x78460436d1d0>),\n",
              " ('ResNet50',\n",
              "  0.40495866537094116,\n",
              "  <keras.src.callbacks.history.History at 0x7847c8233890>),\n",
              " ('EfficientNetB3',\n",
              "  0.35537189245224,\n",
              "  <keras.src.callbacks.history.History at 0x7847b41251d0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2DOHpadkzV_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}