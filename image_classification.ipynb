{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries"
      ],
      "metadata": {
        "id": "yRB3VQ32HLoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import requests\n",
        "import time\n",
        "import gc\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import wandb\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB3, DenseNet169, Xception, ConvNeXtBase\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED = 244\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "wH7LAkk3HPYj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Dataset"
      ],
      "metadata": {
        "id": "GGvsAt4fHSOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Define GitHub Repo & Folder Path"
      ],
      "metadata": {
        "id": "kfQwJ27THqM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_REPO = \"prattapong/Commercial-Airplane-Model-Image-Classification\"\n",
        "GITHUB_FOLDER = \"images\"\n",
        "GITHUB_API_URL = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{GITHUB_FOLDER}\""
      ],
      "metadata": {
        "id": "glwG9gyqHW_H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Fetch Image URLs and Load Image"
      ],
      "metadata": {
        "id": "8n61Mj3zHzKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_sizes = []\n",
        "color_counts = {\"RGB\": 0, \"Grayscale\": 0}"
      ],
      "metadata": {
        "id": "iR8xmDld8NA_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Image URLs Automatically\n",
        "def get_image_urls():\n",
        "    response = requests.get(GITHUB_API_URL)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Error fetching images: {response.json()}\")\n",
        "\n",
        "    image_urls = {}\n",
        "    for folder in response.json():\n",
        "        if folder[\"type\"] == \"dir\":  # Ensure it's a folder (A350, B787, A320)\n",
        "            class_name = folder[\"name\"]\n",
        "            image_urls[class_name] = []\n",
        "            folder_url = folder[\"url\"]\n",
        "\n",
        "            # Fetch image files in each class folder\n",
        "            folder_response = requests.get(folder_url)\n",
        "            if folder_response.status_code == 200:\n",
        "                for file in folder_response.json():\n",
        "                    if file[\"name\"].lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                        image_urls[class_name].append(file[\"download_url\"])\n",
        "\n",
        "    return image_urls\n",
        "\n",
        "# Load Images Function (Now storing original info before resizing)\n",
        "def load_images(image_urls):\n",
        "    IMG_SIZE = (224, 224)  # Resize all images to 224x224\n",
        "    X, y = [], []\n",
        "\n",
        "    total_images = sum(len(urls) for urls in image_urls.values())  # Total number of images\n",
        "    progress_bar = tqdm(total=total_images, desc=\"Loading Images\", unit=\"img\")\n",
        "\n",
        "    for label, urls in image_urls.items():\n",
        "        for url in urls:\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "\n",
        "                # Store original size and color type\n",
        "                original_sizes.append(img.size)  # (width, height)\n",
        "                if img.mode == \"L\":\n",
        "                    color_counts[\"Grayscale\"] += 1\n",
        "                else:\n",
        "                    color_counts[\"RGB\"] += 1\n",
        "\n",
        "                # Convert to RGB and resize\n",
        "                img = img.convert(\"RGB\").resize(IMG_SIZE)\n",
        "                X.append(np.array(img) / 255.0)  # Normalize\n",
        "                y.append(label)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {url}: {e}\")\n",
        "\n",
        "            progress_bar.update(1)  # Update progress bar\n",
        "\n",
        "    progress_bar.close()\n",
        "    return np.array(X), pd.Categorical(y).codes"
      ],
      "metadata": {
        "id": "AVWh-JyZH8i9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_urls = get_image_urls()\n",
        "X, y = load_images(image_urls)  # Load images first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_vXZtrXlX6e",
        "outputId": "f459ff80-0e30-4931-ee8c-668e24db721f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Images:  40%|████      | 240/600 [02:00<03:02,  1.97img/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. EDA"
      ],
      "metadata": {
        "id": "_DcGH7Zi3XVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Display Original Image Size Distribution as DataFrame\n",
        "def display_original_image_sizes(original_sizes):\n",
        "    size_counts = Counter(tuple(size) for size in original_sizes)\n",
        "    size_df = pd.DataFrame(size_counts.items(), columns=[\"Image Size\", \"Frequency\"])\n",
        "    size_df = size_df.sort_values(by=\"Frequency\", ascending=False).reset_index(drop=True)\n",
        "    size_df[\"Percentage\"] = (size_df[\"Frequency\"] / size_df[\"Frequency\"].sum()) * 100\n",
        "    print(size_df)\n",
        "\n",
        "# Function to Show Color vs Grayscale Distribution\n",
        "def plot_color_distribution(color_counts):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.pie(color_counts.values(), labels=color_counts.keys(), autopct=\"%1.1f%%\", colors=[\"lightblue\", \"gray\"])\n",
        "    plt.title(\"Color vs. Grayscale Images (Before Processing)\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to Show Class Distribution After Processing\n",
        "def plot_class_distribution(y):\n",
        "    class_counts = Counter(y)\n",
        "    class_labels = sorted(class_counts.keys())  # Ensure ordered class names\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()), palette=\"viridis\")\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Number of Images\")\n",
        "    plt.title(\"Class Distribution in Dataset\")\n",
        "    plt.xticks(range(len(class_labels)), class_labels, rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Function to Show Sample Images After Processing\n",
        "def show_sample_images(X, y, class_labels, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "    sampled_indices = np.random.choice(len(X), num_images, replace=False)\n",
        "\n",
        "    for i, idx in enumerate(sampled_indices):\n",
        "        axes[i].imshow(X[idx])\n",
        "        axes[i].axis(\"off\")\n",
        "        axes[i].set_title(f\"Class: {class_labels[y[idx]]}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Perform Full EDA\n",
        "def perform_eda(X, y, class_labels):\n",
        "    print(f\"Total images after processing: {len(X)}\")\n",
        "    print(f\"Processed image shape: {X[0].shape}\")  # Should be (224, 224, 3)\n",
        "\n",
        "    display_original_image_sizes(original_sizes)\n",
        "    plot_color_distribution(color_counts)\n",
        "\n",
        "    plot_class_distribution(y)\n",
        "    show_sample_images(X, y, class_labels)"
      ],
      "metadata": {
        "id": "qUzJRJBt9FgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"Airbus A320\", \"Airbus A350\", \"Boeing 787\"]\n",
        "perform_eda(X, y, class_labels)"
      ],
      "metadata": {
        "id": "EzeMGXgM3ZNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data-preprocessing"
      ],
      "metadata": {
        "id": "o2HlslEEIICa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_edges(X):\n",
        "    edge_images = []\n",
        "\n",
        "    for img in X:\n",
        "        gray_img = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
        "        edges = cv2.Canny(gray_img, 1, 20)\n",
        "        edges_rgb = cv2.cvtColor(edges, cv2.COLOR_BGR2RGB)\n",
        "        edge_images.append(edges_rgb / 255.0)\n",
        "\n",
        "    return np.array(edge_images)"
      ],
      "metadata": {
        "id": "aUPzJWBo9gPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_edge = preprocess_edges(X)"
      ],
      "metadata": {
        "id": "SZzU785i90pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_original_vs_edge(X, X_edge, index):\n",
        "    # Plot original image (X[0]) and edge-detected image (X_edge[0])\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Original Image\n",
        "    axes[0].imshow(X[index])\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "\n",
        "    # Edge-Detected Image\n",
        "    axes[1].imshow(X_edge[index])\n",
        "    axes[1].axis(\"off\")\n",
        "    axes[1].set_title(\"Edge-Detected Image\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you already have X (original images) and X_edge (edge-detected images)\n",
        "plot_original_vs_edge(X, preprocess_edges(X), index = 210)"
      ],
      "metadata": {
        "id": "1ZPcWyDu9-Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(X_train):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    return datagen"
      ],
      "metadata": {
        "id": "4Dku3IEFIOwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train model"
      ],
      "metadata": {
        "id": "1V21idVpIl1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 List 5 pre-trained models"
      ],
      "metadata": {
        "id": "gJqMdlyIBeK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS = {\n",
        "    \"ResNet50\": ResNet50,\n",
        "    \"VGG16\": VGG16,\n",
        "    \"DenseNet169\": DenseNet169,\n",
        "    \"Xception\": Xception,\n",
        "    \"ConvNeXtBase\": ConvNeXtBase\n",
        "}"
      ],
      "metadata": {
        "id": "80TWiYyFBo4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 WandB"
      ],
      "metadata": {
        "id": "o2qV682IOaHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize WandB\n",
        "# def init_wandb(project_name=\"commercial-aircraft-model-classification\", entity=\"6620422008-nida-business-school\"):\n",
        "#     wandb.init(project=project_name, entity=\"6620422008-nida-business-school\", reinit=True)\n",
        "\n",
        "def init_wandb(model_name, batch_size, epochs, learning_rate, dropout_rate, num_unfreezed_layer, project_name=\"commercial-aircraft-model-classification\", entity=\"6620422008-nida-business-school\"):\n",
        "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")  # Format: YYYYMMDD-HHMMSS\n",
        "    run_name = f\"{model_name}-BS{batch_size}-LR{learning_rate}-DO{dropout_rate}-UF{num_unfreezed_layer}-{timestamp}\"\n",
        "    wandb.init(project=project_name, entity=entity, name=run_name, reinit=True, resume=False)\n",
        "\n",
        "def train_and_evaluate_model_with_wandb(model_name, X, y, batch_size, epochs, learning_rate, dropout_rate, num_unfreezed_layer=0):\n",
        "    print(f'*** Training {model_name} with WandB ***')\n",
        "    print(f'- Batch Size: {batch_size}')\n",
        "    print(f'- LR: {learning_rate}')\n",
        "    print(f'- Dropout: {dropout_rate}')\n",
        "    print(f'- Last \"{num_unfreezed_layer}\" layers unfreezed\\n')\n",
        "\n",
        "    # Hyperparameters to log with WandB\n",
        "    config = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"dropout_rate\": dropout_rate,\n",
        "        \"num_unfreezed_layer\": num_unfreezed_layer\n",
        "    }\n",
        "\n",
        "    # Initialize WandB for logging\n",
        "    init_wandb(\n",
        "        project_name=\"commercial-aircraft-model-classification\",\n",
        "        entity=\"6620422008-nida-business-school\",\n",
        "        model_name=model_name,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        dropout_rate=dropout_rate,\n",
        "        num_unfreezed_layer=num_unfreezed_layer\n",
        "    )\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        "    )\n",
        "\n",
        "    # Define Input Layer\n",
        "    input_tensor = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Load Pretrained Model\n",
        "    base_model = MODELS[model_name](weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "    # Unfreeze Layers If Needed\n",
        "    if num_unfreezed_layer == 0:\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in base_model.layers[-num_unfreezed_layer:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # Add Custom Classification Head\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    output_layer = tf.keras.layers.Dense(len(np.unique(y)), activation=\"softmax\")(x)\n",
        "\n",
        "    # Build Model\n",
        "    model = tf.keras.Model(inputs=input_tensor, outputs=output_layer)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # Data Augmentation\n",
        "    datagen = augment_data(X_train)\n",
        "\n",
        "    # Model Checkpointing (Save best model)\n",
        "    model_path = f'best_{model_name}.keras'  # Use .keras format\n",
        "    checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    # Train Model with WandB logging for each epoch\n",
        "    # early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_rounds, restore_best_weights=True, verbose=1)\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        history = model.fit(\n",
        "            datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=1,  # Train one epoch at a time\n",
        "            verbose=1,\n",
        "            callbacks=[checkpoint]\n",
        "        )\n",
        "\n",
        "        # Log metrics to WandB after each epoch\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch+1,\n",
        "            \"train_loss\": history.history['loss'][-1],\n",
        "            \"train_accuracy\": history.history['accuracy'][-1],\n",
        "            \"val_loss\": history.history['val_loss'][-1],\n",
        "            \"val_accuracy\": history.history['val_accuracy'][-1]\n",
        "        })\n",
        "\n",
        "    # Load Best Model\n",
        "    custom_objects = get_custom_objects() if model_name == \"ConvNeXtBase\" else None\n",
        "    best_model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "    # Evaluate on Test Data\n",
        "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "    print(f\"\\n{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Log test accuracy to WandB\n",
        "    wandb.log({\"test_accuracy\": test_accuracy})\n",
        "\n",
        "    # Clear session and collect garbage to free memory\n",
        "    K.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return model_name, test_accuracy, history"
      ],
      "metadata": {
        "id": "IR44QBytLs-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters manually\n",
        "model_name = \"Xception\"  # Choose from [ResNet50,VGG16,DenseNet169,Xception,ConvNeXtBase]\n",
        "batch_size = 8\n",
        "epochs = 100\n",
        "learning_rate = 0.001 # Between 0.00001 - 0.01\n",
        "dropout_rate = 0.2 # Between 0.1 - 0.5\n",
        "num_unfreezed_layer = 20 # Greater or equal to 0\n",
        "\n",
        "# Train and evaluate model with WandB logging\n",
        "# early_stopping_rounds = 5\n",
        "train_and_evaluate_model_with_wandb(\n",
        "    model_name=model_name,\n",
        "    X=X,\n",
        "    y=y,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    learning_rate=learning_rate,\n",
        "    dropout_rate=dropout_rate,\n",
        "    # early_stopping_rounds=early_stopping_rounds,\n",
        "    num_unfreezed_layer=num_unfreezed_layer\n",
        ")"
      ],
      "metadata": {
        "id": "0VItSFxdLzxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Show result of a sample"
      ],
      "metadata": {
        "id": "lYXfZpDkND7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradcam(model, img_array, layer_name):\n",
        "    \"\"\"\n",
        "    Computes Grad-CAM heatmap for a given image and model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model\n",
        "    - img_array: Preprocessed image array with shape (1, height, width, channels)\n",
        "    - layer_name: The name of the convolutional layer to extract gradients from\n",
        "\n",
        "    Returns:\n",
        "    - heatmap: Grad-CAM heatmap (numpy array)\n",
        "    \"\"\"\n",
        "    grad_model = Model(inputs=model.input, outputs=[model.get_layer(layer_name).output, model.output])\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    for i in range(conv_outputs.shape[-1]):\n",
        "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
        "\n",
        "    heatmap = np.mean(conv_outputs, axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)  # ReLU\n",
        "    heatmap /= np.max(heatmap)  # Normalize\n",
        "    return heatmap\n",
        "\n",
        "def overlay_heatmap(img, heatmap, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Overlays the Grad-CAM heatmap on the original image.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Original image\n",
        "    - heatmap: Grad-CAM heatmap\n",
        "    - alpha: Transparency factor (default=0.5)\n",
        "\n",
        "    Returns:\n",
        "    - Superimposed image with heatmap\n",
        "    \"\"\"\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "    return superimposed_img\n",
        "\n",
        "def show_prediction_with_gradcam(model, X, y, index, class_labels, layer_name=\"convnext_base_stage4_block2_layer_scale\"):\n",
        "    \"\"\"\n",
        "    Displays an image with the model's prediction, actual label, and Grad-CAM visualization.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model\n",
        "    - X: NumPy array of images\n",
        "    - y: NumPy array of actual labels\n",
        "    - index: Index of the image to display\n",
        "    - class_labels: List of class names corresponding to label indices\n",
        "    - layer_name: Name of the convolutional layer to compute Grad-CAM from (default: last ConvNeXt block)\n",
        "    \"\"\"\n",
        "    sample_image = np.array(X[index])\n",
        "    sample_input = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    predictions = model.predict(sample_input)\n",
        "    predicted_class = np.argmax(predictions)\n",
        "    actual_class = y[index]\n",
        "\n",
        "    predicted_label = class_labels[predicted_class]\n",
        "    actual_label = class_labels[actual_class]\n",
        "\n",
        "    # Compute Grad-CAM\n",
        "    heatmap = compute_gradcam(model, sample_input, layer_name)\n",
        "    superimposed_img = overlay_heatmap((sample_image * 255).astype(np.uint8), heatmap)\n",
        "\n",
        "    # Display Results\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "    # Original Image\n",
        "    axes[0].imshow(sample_image)\n",
        "    axes[0].axis(\"off\")\n",
        "    axes[0].set_title(f\"Original Image\\nActual: {actual_label}\\nPredicted: {predicted_label}\", fontsize=12, color=\"blue\")\n",
        "\n",
        "    # Grad-CAM Overlay\n",
        "    axes[1].imshow(superimposed_img)\n",
        "    axes[1].axis(\"off\")\n",
        "    axes[1].set_title(\"Grad-CAM Visualization\", fontsize=12, color=\"red\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3o018kM6J0F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"Airbus A320\", \"Airbus A350\", \"Boeing 787\"]\n",
        "# best_model = tf.keras.models.load_model(\"best_DenseNet169.h5\")"
      ],
      "metadata": {
        "id": "cmE4GLemLut0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [0,10,402,405,500, 600]:\n",
        "    show_prediction(best_model, X, y, index=i, class_labels=class_labels)"
      ],
      "metadata": {
        "id": "SPUxEBgmbz8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "id": "hbGq6N81MqyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2DOHpadkzV_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}