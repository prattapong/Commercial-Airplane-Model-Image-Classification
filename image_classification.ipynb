{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Libraries"
      ],
      "metadata": {
        "id": "yRB3VQ32HLoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB3, DenseNet169, Xception, ConvNeXtBase\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED = 244\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "wH7LAkk3HPYj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Dataset"
      ],
      "metadata": {
        "id": "GGvsAt4fHSOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Define GitHub Repo & Folder Path"
      ],
      "metadata": {
        "id": "kfQwJ27THqM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GITHUB_REPO = \"prattapong/Commercial-Airplane-Model-Image-Classification\"\n",
        "GITHUB_FOLDER = \"images\"\n",
        "GITHUB_API_URL = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{GITHUB_FOLDER}\""
      ],
      "metadata": {
        "id": "glwG9gyqHW_H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Fetch Image URLs and Load Image"
      ],
      "metadata": {
        "id": "8n61Mj3zHzKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Image URLs Automatically\n",
        "def get_image_urls():\n",
        "    response = requests.get(GITHUB_API_URL)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Error fetching images: {response.json()}\")\n",
        "\n",
        "    image_urls = {}\n",
        "    for folder in response.json():\n",
        "        if folder[\"type\"] == \"dir\":  # Ensure it's a folder (A350, B787, A320)\n",
        "            class_name = folder[\"name\"]\n",
        "            image_urls[class_name] = []\n",
        "            folder_url = folder[\"url\"]\n",
        "\n",
        "            # Fetch image files in each class folder\n",
        "            folder_response = requests.get(folder_url)\n",
        "            if folder_response.status_code == 200:\n",
        "                for file in folder_response.json():\n",
        "                    if file[\"name\"].lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                        image_urls[class_name].append(file[\"download_url\"])\n",
        "\n",
        "    return image_urls\n",
        "\n",
        "# Load Images Using Image.open()\n",
        "def load_images(image_urls):\n",
        "    IMG_SIZE = (224, 224)  # Resize all images to 224x224\n",
        "    X, y = [], []\n",
        "\n",
        "    total_images = sum(len(urls) for urls in image_urls.values())  # Total number of images\n",
        "    progress_bar = tqdm(total=total_images, desc=\"Loading Images\", unit=\"img\")\n",
        "\n",
        "    for label, urls in image_urls.items():\n",
        "        for url in urls:\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(BytesIO(response.content)).convert(\"RGB\")  # Load image\n",
        "                img = img.resize(IMG_SIZE)\n",
        "                X.append(np.array(img) / 255.0)  # Normalize\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {url}: {e}\")\n",
        "            progress_bar.update(1)  # Update progress bar\n",
        "\n",
        "    progress_bar.close()\n",
        "    return np.array(X), pd.Categorical(y).codes"
      ],
      "metadata": {
        "id": "AVWh-JyZH8i9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_urls = get_image_urls()\n",
        "X, y = load_images(image_urls)"
      ],
      "metadata": {
        "id": "t_vXZtrXlX6e",
        "outputId": "f1255372-15f8-4e87-da8d-65c22ad32673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Images:  10%|â–‰         | 58/605 [00:16<02:23,  3.82img/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data-preprocessing"
      ],
      "metadata": {
        "id": "o2HlslEEIICa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(X_train):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    return datagen"
      ],
      "metadata": {
        "id": "4Dku3IEFIOwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train model"
      ],
      "metadata": {
        "id": "1V21idVpIl1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 List 5 pre-trained models"
      ],
      "metadata": {
        "id": "gJqMdlyIBeK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODELS = {\n",
        "    \"ResNet50\": ResNet50,\n",
        "    \"EfficientNetB3\": EfficientNetB3,\n",
        "    \"DenseNet169\": DenseNet169,\n",
        "    \"Xception\": Xception,\n",
        "    \"ConvNeXtBase\": ConvNeXtBase\n",
        "}"
      ],
      "metadata": {
        "id": "80TWiYyFBo4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Initiate training loop"
      ],
      "metadata": {
        "id": "u4xXQzZrPWqO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdI2QyIrpTO0"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(model_name, X, y, batch_size, epochs, learning_rate, dropout_rate, num_unfreezed_layer=0):\n",
        "    print(f'*** Training {model_name} ***')\n",
        "    print(f'- Batch Size: {batch_size}')\n",
        "    print(f'- LR: {learning_rate}')\n",
        "    print(f'- Dropout: {dropout_rate}')\n",
        "    print(f'- Last \"{num_unfreezed_layer}\" layers unfreezed\\n')\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        "    )\n",
        "\n",
        "    # Define Input Layer\n",
        "    input_tensor = Input(shape=(224, 224, 3))\n",
        "\n",
        "    # Load Pretrained Model\n",
        "    base_model = MODELS[model_name](weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "    # Unfreeze Layers If Needed\n",
        "    if num_unfreezed_layer == 0:\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in base_model.layers[-num_unfreezed_layer:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    # Add Custom Classification Head\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    output_layer = Dense(len(np.unique(y)), activation=\"softmax\")(x)\n",
        "\n",
        "    # Build Model\n",
        "    model = Model(inputs=input_tensor, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # Data Augmentation\n",
        "    datagen = augment_data(X_train)\n",
        "\n",
        "    # Model Checkpointing\n",
        "    model_path = f'best_{model_name}.h5'  # Use .keras format\n",
        "    checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    # Train Model\n",
        "    history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        epochs=epochs,\n",
        "                        callbacks=[checkpoint])\n",
        "\n",
        "    # Load Best Model (Fix for ConvNeXtBase)\n",
        "    custom_objects = get_custom_objects() if model_name == \"ConvNeXtBase\" else None\n",
        "    best_model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
        "\n",
        "    # Evaluate on Test Data\n",
        "    test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "    print(f\"\\n{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    return model_name, test_accuracy, history\n",
        "\n",
        "def compare_models(X, y, learning_rates, dropout_rates, batch_sizes, num_unfreezed_layers, epochs=50):\n",
        "    results = []\n",
        "\n",
        "    # Loop through all model hyperparameters with tqdm progress bar\n",
        "    for model_name in MODELS.keys():\n",
        "        for lr in learning_rates:\n",
        "            for dr in dropout_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    for num_unfreezed_layer in num_unfreezed_layers:\n",
        "                        result = train_and_evaluate_model(model_name, X, y, batch_size, epochs, lr, dr, num_unfreezed_layer)\n",
        "                        results.append(result)\n",
        "                        print('------------------------------------------------------------------------\\n')\n",
        "\n",
        "    # Sort models by accuracy\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    print(\"\\nModel Performance Ranking:\")\n",
        "    for rank, (model_name, accuracy, _) in enumerate(results, 1):\n",
        "        print(f\"{rank}. {model_name}: {accuracy:.4f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrOJ7-6epTO3"
      },
      "outputs": [],
      "source": [
        "# image_urls = get_image_urls()\n",
        "# X, y = load_images(image_urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Set Hyper-parameter"
      ],
      "metadata": {
        "id": "OwwQZAAiRlKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_unfreezed_layers = [0]\n",
        "learning_rates = [0.0001]\n",
        "dropout_rates = [0.2]\n",
        "batch_sizes = [8]"
      ],
      "metadata": {
        "id": "f33W2VbrQjkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Train all models and parameters"
      ],
      "metadata": {
        "id": "Ahnvvdu-Safq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = compare_models(\n",
        "    X = X,\n",
        "    y = y,\n",
        "    epochs = 5,\n",
        "\n",
        "    ############## Hyper-parameter ##############\n",
        "    learning_rates = learning_rates,\n",
        "    dropout_rates = dropout_rates,\n",
        "    batch_sizes = batch_sizes,\n",
        "    num_unfreezed_layers = num_unfreezed_layers\n",
        ")"
      ],
      "metadata": {
        "id": "aP6gUIceJRCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Show result of a sample"
      ],
      "metadata": {
        "id": "lYXfZpDkND7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_prediction(model, X, y, index, class_labels):\n",
        "    \"\"\"\n",
        "    Displays an image from X[index] with the model's predicted and actual label.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model\n",
        "    - X: NumPy array of images\n",
        "    - y: NumPy array of actual labels\n",
        "    - index: Index of the image to display\n",
        "    - class_labels: List of class names corresponding to label indices\n",
        "    \"\"\"\n",
        "    sample_image = np.array(X[index])\n",
        "    sample_input = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "    predicted_class = np.argmax(model.predict(sample_input))\n",
        "    actual_class = y[index]\n",
        "\n",
        "    predicted_label = class_labels[predicted_class]\n",
        "    actual_label = class_labels[actual_class]\n",
        "\n",
        "    # Display the image with prediction\n",
        "    plt.imshow(sample_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Predicted: {predicted_label}\\nActual: {actual_label}\", fontsize=12, color=\"blue\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3o018kM6J0F-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\"Airbus A320\", \"Airbus A350\", \"Boeing 787\"]\n",
        "best_model = tf.keras.models.load_model(\"best_DenseNet169.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "cmE4GLemLut0",
        "outputId": "58d1c55b-64b0-4c3c-e05a-060a0de81be6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'best_DenseNet169.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-597daf44b03a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Airbus A320\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Airbus A350\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Boeing 787\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_DenseNet169.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'best_DenseNet169.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [0,10,402,405,500, 600]:\n",
        "    show_prediction(best_model, X, y, index=i, class_labels=class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "SPUxEBgmbz8C",
        "outputId": "cbf80df2-bf9c-4d17-c52a-eff02cde5d12"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'predict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-05c91130c4e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m402\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m405\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mshow_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-d18a2b6069c8>\u001b[0m in \u001b[0;36mshow_prediction\u001b[0;34m(model, X, y, index, class_labels)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msample_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mactual_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'predict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "id": "hbGq6N81MqyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6a63c2-6c67-40ac-e4b6-815d422072f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('DenseNet169',\n",
              "  0.6363636255264282,\n",
              "  <keras.src.callbacks.history.History at 0x78474e749150>),\n",
              " ('Xception',\n",
              "  0.4958677589893341,\n",
              "  <keras.src.callbacks.history.History at 0x784605569ed0>),\n",
              " ('ConvNeXtBase',\n",
              "  0.4628099203109741,\n",
              "  <keras.src.callbacks.history.History at 0x78460436d1d0>),\n",
              " ('ResNet50',\n",
              "  0.40495866537094116,\n",
              "  <keras.src.callbacks.history.History at 0x7847c8233890>),\n",
              " ('EfficientNetB3',\n",
              "  0.35537189245224,\n",
              "  <keras.src.callbacks.history.History at 0x7847b41251d0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2DOHpadkzV_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}