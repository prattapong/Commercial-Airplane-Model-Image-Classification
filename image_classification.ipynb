{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kdI2QyIrpTO0",
        "outputId": "04a91d3a-d3f7-4b62-93be-b7f971e748da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Error fetching images: {'message': 'Not Found', 'documentation_url': 'https://docs.github.com/rest/repos/contents#get-repository-content', 'status': '404'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-30dcd1c3c2f0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# Run the process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mimage_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Automatically fetch image URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_urls\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load images using Image.open()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Train deep learning model with data augmentation and save best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-30dcd1c3c2f0>\u001b[0m in \u001b[0;36mget_image_urls\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGITHUB_API_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error fetching images: {response.json()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mimage_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Error fetching images: {'message': 'Not Found', 'documentation_url': 'https://docs.github.com/rest/repos/contents#get-repository-content', 'status': '404'}"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Define GitHub Repo & Folder Path\n",
        "GITHUB_REPO = \"prattapong/Commercial-Airplane-Model-Image-Classification\"\n",
        "GITHUB_FOLDER = \"images\"\n",
        "GITHUB_API_URL = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{GITHUB_FOLDER}\"\n",
        "\n",
        "# Step 2: Fetch Image URLs Automatically\n",
        "def get_image_urls():\n",
        "    response = requests.get(GITHUB_API_URL)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Error fetching images: {response.json()}\")\n",
        "\n",
        "    image_urls = {}\n",
        "    for folder in response.json():\n",
        "        if folder[\"type\"] == \"dir\":  # Ensure it's a folder (A350, B787, A320)\n",
        "            class_name = folder[\"name\"]\n",
        "            image_urls[class_name] = []\n",
        "            folder_url = folder[\"url\"]\n",
        "\n",
        "            # Fetch image files in each class folder\n",
        "            folder_response = requests.get(folder_url)\n",
        "            if folder_response.status_code == 200:\n",
        "                for file in folder_response.json():\n",
        "                    if file[\"name\"].lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                        image_urls[class_name].append(file[\"download_url\"])\n",
        "\n",
        "    return image_urls\n",
        "\n",
        "# Step 3: Load Images Using Image.open()\n",
        "def load_images(image_urls):\n",
        "    IMG_SIZE = (224, 224)  # Resize all images to 224x224\n",
        "    X, y = [], []\n",
        "\n",
        "    for label, urls in image_urls.items():\n",
        "        for url in urls:\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(BytesIO(response.content)).convert(\"RGB\")  # Load image\n",
        "                img = img.resize(IMG_SIZE)  # Resize\n",
        "                X.append(np.array(img) / 255.0)  # Normalize\n",
        "                y.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {url}: {e}\")\n",
        "\n",
        "    return np.array(X), pd.Categorical(y).codes  # Convert labels to numeric\n",
        "\n",
        "# Step 4: Data Augmentation\n",
        "def augment_data(X_train):\n",
        "    # Create an ImageDataGenerator for augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    # Fit the generator to the training data\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    return datagen\n",
        "\n",
        "# Step 5: Train Model Using ResNet50 with Augmentation\n",
        "def train_model(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze pretrained layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add classification layers\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation=\"relu\")(x)\n",
        "    x = Dense(len(set(y)), activation=\"softmax\")(x)  # Output layer for classification\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "    # Build the model\n",
        "    model.build((None, 224, 224, 3))  # Build the model with the input shape\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    # Perform data augmentation\n",
        "    datagen = augment_data(X_train)\n",
        "\n",
        "    # Set up ModelCheckpoint to save the best model\n",
        "    checkpoint = ModelCheckpoint('best_airplane_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "    # Train model using augmented data\n",
        "    model.fit(datagen.flow(X_train, y_train, batch_size=32), validation_data=(X_test, y_test), epochs=10, callbacks=[checkpoint])\n",
        "\n",
        "    # Load and print the best model\n",
        "    best_model = tf.keras.models.load_model('best_airplane_model.h5')\n",
        "    print(\"Best model saved as 'best_airplane_model.h5'\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# Run the process\n",
        "image_urls = get_image_urls()  # Automatically fetch image URLs\n",
        "X, y = load_images(image_urls)  # Load images using Image.open()\n",
        "best_model = train_model(X, y)  # Train deep learning model with data augmentation and save best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrOJ7-6epTO3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}